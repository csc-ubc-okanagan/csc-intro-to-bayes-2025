---
title: "A math-light introduction to Bayesian statistics"
author: "Stefano Mezzini"
date: "2025-02-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library('dplyr')
library('tidyr')
library('ggplot2')
PAL <- khroma::color('highcontrast')(3) # prior, likelihood, and posterior
PAL[3] <- 'darkgreen'
# set default ggplot theme
theme_set(theme_bw() +
            theme(legend.position = 'none',
                  text = element_text(size = 15),
                  panel.grid = element_blank()))
A <- 0.4
```

# Priors: an opinion before data collection

Imagine you have a cat (or a dog, if that helps -- just read all mentions of "cat" as "dog"). One day you come home to find a framed picture on the floor; the frame broken and the glass cracked. Did your cat break it? Before you start collecting any information, you may already have an opinion about whether or not it did. If you have no information at all, you may say the chances of it being guilty are the same as it being innocent. You may also say the same if you have some information but are highly uncertain. If you believe your cat is likely innocent, you would place a larger probability on it being innocent, and you would place less if you believe it to be guilty.

```{r}
expand_grid(status = c('Innocent', 'Guilty') %>%
              factor(., levels = .),
            prior_name = c('No information', 'Uncertain', 'Likely innocent', 'Likely guilty') %>%
              factor(., levels = .)) %>%
  mutate(prior = case_when(
    prior_name == 'No information' & status == 'Guilty' ~ 0.5,
    prior_name == 'No information' & status != 'Guilty' ~ 0.5,
    prior_name == 'Uncertain' & status == 'Guilty' ~ 0.5,
    prior_name == 'Uncertain' & status != 'Guilty' ~ 0.5,
    prior_name == 'Likely innocent' & status == 'Guilty' ~ 0.2,
    prior_name == 'Likely innocent' & status != 'Guilty' ~ 0.8,
    prior_name == 'Likely guilty' & status == 'Guilty' ~ 0.8,
    prior_name == 'Likely guilty' & status != 'Guilty' ~ 0.2)) %>%
  ggplot() +
  facet_wrap(~ prior_name) +
  geom_bar(aes(status, prior), fill = 'grey', color = 'black', lwd = 1,
           alpha = A, stat = 'identity') +
  labs(x = NULL, y = 'Probability mass') +
  ylim(c(0, 1))
```

However, how do you distinguish between having no information at all about the cat and having some small amount of information? And how do you express your uncertainty in your initial guess? We can do this by expressing our prior belief as a distribution rather than a single value. You could say that this distribution is your entire belief state (the most likely value and the uncertainty around it) prior to any data collection, which we will call your **prior** for short. If use $\theta$ to indicate the **probability of your cat breaking the frame** (note: not just whether it broke it or not), $\text{P(guilty)}$, your prior may look like one of the distributions below.

```{r}
d <- expand_grid(theta = seq(0, 1, by = 0.001),
            prior_name = c('No information', 'Uncertain', 'Likely innocent', 'Likely guilty') %>%
              factor(., levels = .)) %>%
  mutate(prior = case_when(prior_name == 'No information' ~ dbeta(theta, 1, 1),
                          prior_name == 'Uncertain' ~ dbeta(theta, 1.5, 1.5),
                          prior_name == 'Likely innocent' ~ dbeta(theta, 2, 5),
                          prior_name == 'Likely guilty' ~ dbeta(theta, 5, 2)))

ggplot(d) +
  facet_wrap(~ prior_name) +
  geom_area(aes(theta, prior), fill = PAL[1], color = PAL[1], lwd = 1, alpha = A) +
  labs(x = expression(P(guilty)==theta),
       y = expression(Probability~density~of~theta))
```

Now you can see how the "no information" prior is different from the "uncertain" prior. The "no information prior" says that all values of $\theta$ are equally as likely (including always being guilty, $\theta = 1$, and always being innocent, $\theta = 0$), while the "uncertain" prior recognizes the uncertainty by setting the most likely value to $\theta = 0.5$ while stating that it is impossible for the cat to *always* be guilty or innocent -- maybe you hung the picture poorly, but sometimes cats *do* break things. Unlike Beyesian statistics, the Frequentist approach to statistics (the "traditional" hypothesis testing approach with $H_0$, $H_a$, and $p$-values) always starts with no prior information, i.e. the "flat prior".

# Likelihood: the information in the data

Once you have defined your prior, it is time to collect some data so you can update your belief based on the evidence. To do this, you may inspect the frame and the area around it. Is anything else out of order? Are other objects knocked down? Could your cat have reached the frame? The answer to each of these questions can be summarized into a new distribution: the likelihood. The likelihood contains all the information you gathered from inspecting the scene (or running an experiment). Formally, it is the probability of obtaining the information (or data, $D$) you obtained, for some value of $\theta$, and we can write it as $P(D | \theta)$. This is what the Frequentist approach to statistics is based on: $p$-values are the probability of observing the dataset you observed or a more unlikely one, if $\theta$ has the value specified by the null hypothesis, which we can write as $P(D|H_0: \theta = \theta_0)$. If you calculate $P(D|\theta = \theta_i)$ for all possible values of $\theta$ rather than just the value from $H_0$, you get the probability distribution of $D$ conditional on $\theta$, which is the likelihood $P(D|\theta)$.

When you inspect the objects around the frame, you notice that other things are knocked over, and the nail the frame was hanging from seems to have have given out due to excessive weight. In this case, the likelihood may look like something like this:

```{r}
d$likelihood <- dbeta(d$theta, 15, 10)

d %>%
  filter(prior_name == prior_name[1]) %>%
  ggplot() +
  geom_area(aes(theta, likelihood), fill = PAL[2], color = PAL[2], lwd = 1, alpha = A) +
  geom_vline(xintercept = 0.5, lty = 'dashed') +
  labs(y = expression('Likelihood,'~P(D~'|'~theta)),
       x = expression(theta))
```

It seems reasonable to believe that the cat did indeed cause the frame to fall, since would be fairly unlikely to observe this evidence if the cat is most probably innocent ($P(\theta < 0.5$). Consequently, most of the likelihood density is for $\theta > 0.5$, with $\theta = 0.5$ being a 50-50 change of the cat being guilty. But could this just be an accident that happened due to chance? Maybe the frame wasn't hung properly, and when it fell it scared the cat, who then knocked the other items down. Fortunately, we can combine the likelihood with our prior to estimate the probability that the cat did indeed knock the frame off the wall.

# Posterior: your updated belief

What is the probability that your cat knocked the frame off the wall, given your guess before observing the evidence? Since both the likelihood and the prior are probability distributions, we can combine them by taking the product of the two. More specifically, we can apply Bayes' theorem to calculate the probability of the cat being guilty, given the evidence (which is different different from the likelihood!). Mathematically, we can write it as

$$P(\theta | D) = \frac{P(\theta)~P(D|\theta)}{P(D)},$$

where $P(\theta)$ is our prior, $P(D|\theta)$ is our likelihood, and $P(D)$ is the probability of observing the evidence we observed, irrespective of $\theta$ (i.e., averaged across all possible values of $\theta$). We haven't talked about $P(D)$ yet, but this is not an issue. The probability of observing the scene we observed is a number we can figure out and cancel out by making sure the total area for $P(\theta|D)$ is equal to 1. Mathematically, this means that $\int_DP(\theta|D) \, dD = 1$, but you don't have to worry about doing any calculations. Through some simulations and "mathematical magic" (e.g., the [Metropolisâ€“Hastings algorithm](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm)), we can approximate $P(\theta|D)$ without complex (and possibly unsolvable) integrals. If we calculate the posterior using each of our priors from before, we get the following figure:

```{r}
d$posterior <- d$prior * d$likelihood # check flat prior for comparison to likelihood

d %>%
  ggplot() +
  facet_wrap(~ prior_name) +
  geom_area(aes(theta, posterior), fill = PAL[3], color = PAL[3], lwd = 1, alpha = A) +
  geom_vline(xintercept = 0.5, lty = 'dashed') +
  labs(x = expression(theta),
       y = expression('Posterior,'~P(D~'|'~theta)))
```

As you can see, your starting belief impacts whether or not you believe your cat was guilty, even after seeing the evidence, but in each case you believe them to be most probably guilty. The table below summarizes how certain you are the cat is guilty, based on your prior. In each case, you are more than 50% sure that the cat did break the frame, but you are less inclined to think so if you initially believed it to be innocent. In contrast, you are more than 90% certain it is guilty if you started from with the "likely guilty" prior. Note that if you started with no information (i.e., a flat prior), your posteiror looks identical to your likelihood.

```{r posteriors, echo = FALSE}
d %>%
  group_by(prior_name) %>%
  summarize(certainty_guilty = sum(posterior * (theta >= 0.5)) / sum(posterior)) %>%
  rename(Prior = prior_name, 'Certainty of guilty verdict' = certainty_guilty) %>%
  knitr::kable(format = 'pipe', digits = 2, caption = "**Table 1:** Degree of certainty that the cat broke the frame, based on your prior.")
```

***HERE***

i hope i have convinced you that bayes is intuitive and similar to our thought process... the posterior is just our belief state after collecting evidence and our degree of certainty


# Bayesian updating: when posteriors become the new priors



# Competing hypotheses: multiple cats


# add another example: estimating mean weight of cats in a colony
